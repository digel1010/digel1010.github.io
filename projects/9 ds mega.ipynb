{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "\n",
    "Tienes acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos (del proyecto del sprint de Análisis estadístico de datos). Para esta tarea de clasificación debes crear un modelo que escoja el plan correcto. Como ya hiciste el paso de procesar los datos, puedes lanzarte directo a crear el modelo.\n",
    "\n",
    "Desarrolla un modelo con la mayor exactitud posible. En este proyecto, el umbral de exactitud es 0.75. Usa el dataset para comprobar la exactitud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el area de las telecomunicaciones es importante la adaptación a las necesidades de los clientes para mantener una ventaja competitiva. La compañía móvil Megaline ha identificado una oportunidad para optimizar la satisfacción del cliente y mejorar la eficiencia de sus ofertas de planes mediante el uso de modelos predictivos. Actualmente, muchos de sus clientes continúan utilizando planes antiguos, lo que podría limitar el valor que reciben tanto ellos como la empresa.\n",
    "\n",
    "la compañía desea desarrollar un modelo predictivo que analice el comportamiento de los clientes y recomiende el plan más adecuado. Utilizando datos históricos de clientes que ya han cambiado a los nuevos planes, el objetivo es crear un modelo de clasificación con una exactitud mínima de 0.75. Este modelo permitirá personalizar las recomendaciones y mejorar la satisfacción del cliente, facilitando una transición hacia las nuevas ofertas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos todas las librerias que creemos que vamos a utilizar\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el archivo en un dataframe\n",
    "\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3214, 5)\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "#validamos las dimensiones del dataframe (usamos shape) e imprimimos las primeras filas (usamos head)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print()\n",
    "\n",
    "#mostramos la informacion del dataframe con el metodo info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# se valida si tenemos duplicados en el dataframe con el metodo duplicated.\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# se valida si tenemos valores ausentes en el dataframe con el metodo isna.\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comportamiento estadístico de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Mostramos un resumen estadístico de las variables utilizando el metodo describe\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se valida el dataframe mostrando la informacion con el metodo info, en el cual evidenciamos que los tipos de datos de cada columna son correctos. adicionalmente se revisa si tenemos duplicados o valores ausentes lo cual nos da cero para ambos aspectos, ademas se realiza un resumen estadistico del dataframe llamando al metodo describe, en el cual podemos ver informacion estadistica como el promedio, valores minimos y maximos, desviacion estandar, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establecemos variables separadas para nuestras caracteristicas y para nuestro objetivo\n",
    "\n",
    "features = df.drop(['is_ultra'], axis= 1)\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no tenemos conjunto de prueba. los datos fuentes se dividiran en 3(entrenamiento, validacion y prueba).\n",
    "\n",
    "# dividimos el entrenamiento (60%) y un conjunto combinado de validación/prueba (40%)\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=0.40, random_state=12345)\n",
    "\n",
    "# ahora dividimos el conjunto combinado (40%) en la mitad para obtener validacion 20% y prueba 20%\n",
    "features_val, features_test, target_val, target_test = train_test_split(features_temp, target_temp, test_size=0.50, random_state=12345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calidad de diferentes modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7542768273716952\n",
      "max_depth = 2 : 0.7822706065318819\n",
      "max_depth = 3 : 0.7853810264385692\n",
      "max_depth = 4 : 0.7791601866251944\n",
      "max_depth = 5 : 0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "#iteraremos diferentes valores del hiperparametro max_depth con un bucle y compararemos la calidad de las diferentes versiones\n",
    "\n",
    "for depth in range(1, 6):\n",
    "        model_1 = DecisionTreeClassifier(random_state=12345, max_depth=depth) \n",
    "        model_1.fit(features_train, target_train)  # entrenamos el modelo\n",
    "\n",
    "        predictions_val = model_1.predict(features_val) # encontramos las predicciones usando el conjunto de validación\n",
    "\n",
    "        print(\"max_depth =\", depth, \": \", end='')\n",
    "        print(accuracy_score(target_val, predictions_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo bosque aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de validación (n_estimators = 40): 0.80248833592535\n"
     ]
    }
   ],
   "source": [
    "# hacemos un bucle que pruebe modelos de bosque aleatorio con varios números de estimadores.\n",
    "\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 50): # seleccionamos el rango del hiperparámetro\n",
    "    model_2 = RandomForestClassifier(random_state=54321, n_estimators= est) # configuramos el número de árboles\n",
    "    model_2.fit(features_train, target_train) # entrenamos el modelo\n",
    "    \n",
    "    score = model_2.score(features_val, target_val) # calculamos la puntuación de accuracy en el conjunto de validación\n",
    "    if score > best_score:\n",
    "        best_score = score # guarda la mejor puntuación de accuracy en el conjunto de validación\n",
    "        best_est = est # guarda el número de estimadores que corresponden a la mejor puntuación de exactitud\n",
    "\n",
    "print(\"La exactitud del mejor modelo en el conjunto de validación (n_estimators = {}): {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo de regresión logística en el conjunto de entrenamiento: 0.7505186721991701\n",
      "Accuracy del modelo de regresión logística en el conjunto de validación: 0.7589424572317263\n"
     ]
    }
   ],
   "source": [
    "# Iniciamos el modelo de regresion logistica con los parámetros random_state=54321 y solver='liblinear'\n",
    "model_3 = LogisticRegression(random_state=54321, solver='liblinear') \n",
    "\n",
    "model_3.fit(features_train, target_train) # entrenamos el modelo\n",
    "score_train = model_3.score(features_train, target_train) # calculamos la puntuación de accuracy en el conjunto de entrenamiento\n",
    "score_val = model_3.score(features_val, target_val) # calculamos la puntuación de accuracy en el conjunto de validación\n",
    "\n",
    "print(\"Accuracy del modelo de regresión logística en el conjunto de entrenamiento:\", score_train)\n",
    "print(\"Accuracy del modelo de regresión logística en el conjunto de validación:\", score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de bosque aleatorio con n_estimators=40 resultó ser el modelo más preciso en este experimento, logrando una exactitud de 0.8024 en el conjunto de validación. Este indicaria que este modelo tiene una mejor capacidad para capturar las relaciones complejas en los datos, debido a la combinación de múltiples árboles de decisión.\n",
    "\n",
    "El árbol de decisión fue también competitivo, con un buen rendimiento en max_depth=3, pero no alcanzó la precisión del bosque aleatorio.\n",
    "\n",
    "La regresión logística fue el modelo menos preciso en este caso, aunque rápida y eficiente, no se ajustó tan bien como los otros modelos más complejos, posiblemente debido a la naturaleza no lineal de los datos.\n",
    "\n",
    "De acuero a lo anterior, se recomendaría utilizar el modelo de bosque aleatorio con n_estimators=40 para la evaluación final en el conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calidad del modelo usando el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo de bosque aleatorio en el conjunto de prueba: 0.7931570762052877\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo de bosque aleatorio con n_estimators=40\n",
    "\n",
    "final_model = RandomForestClassifier(random_state=54321, n_estimators=40)\n",
    "final_model.fit(features_train, target_train)  # Entrenamos el modelo con el conjunto de entrenamiento\n",
    "   \n",
    "# Hacemos predicciones con el conjunto de prueba\n",
    "predictions_test = final_model.predict(features_test)\n",
    "\n",
    "# Calculamos la precisión del modelo en el conjunto de prueba\n",
    "test_accuracy = accuracy_score(target_test, predictions_test)\n",
    "\n",
    "# Mostramos la precisión\n",
    "print(f\"Exactitud del modelo de bosque aleatorio en el conjunto de prueba: {test_accuracy:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de cordura al modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para asegurar que nuestro modelo entrenado tiene valor real y no está simplemente haciendo predicciones aleatorias podemos hacer la validacion con una prueba de cordura. Podriamos utilizar DummyClassifier que siempre predice la clase más frecuente (valor mas frecuente de nuestra variable objetivo), y comparamos su rendimiento con nuestro modelo real.\n",
    "\n",
    "Si nuestro modelo de bosque aleatorio supera claramente al modelo dummy, podemos decir que nuestro modelo de bosque aleatorio no está haciendo predicciones aleatorias e indicaria que si esta capturando patrones en los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo Dummy: 0.6842923794712286\n"
     ]
    }
   ],
   "source": [
    "# Creamos un modelo \"Dummy\" que siempre prediga la clase mas frecuente de nuestra variable objetivo (is_ultra)\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_model = DummyClassifier(strategy='most_frequent', random_state=12345)\n",
    "dummy_model.fit(features_train, target_train) # Entrenamos el modelo con el conjunto de entrenamiento\n",
    "\n",
    "dummy_score = dummy_model.score(features_test, target_test) # evaluamos en el conjunto de prueba\n",
    "\n",
    "print(f'Exactitud del modelo Dummy: {dummy_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de bosque aleatorio fue el mejor para la tarea de clasificación entre los planes Smart y Ultra, con una exactitud consistente tanto en los conjuntos de validación como de prueba.\n",
    "\n",
    "La exactitud final del 0.793 en el conjunto de prueba es adecuada para las necesidades de la compañía, ya que superó el umbral de 0.75 exigido.\n",
    "\n",
    "al comparar con el clasificador dummy demuestra que el modelo realmente ha aprendido a diferenciar entre las dos clases basándose en las características del comportamiento de los usuarios.\n",
    "\n",
    "el modelo de bosque aleatorio es una herramienta efectiva para predecir si un usuario debería tener el plan Smart o Ultra, ya que se basa en sus patrones de uso de llamadas, mensajes y datos. Esto ayudará a Megaline para orientar a los usuarios hacia el plan más adecuado para ellos.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 748,
    "start_time": "2024-09-11T14:45:40.964Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-11T14:49:06.490Z"
   },
   {
    "duration": 225,
    "start_time": "2024-09-11T14:51:26.233Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-11T14:51:49.812Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-11T15:26:41.570Z"
   },
   {
    "duration": 18,
    "start_time": "2024-09-11T15:32:31.849Z"
   },
   {
    "duration": 2,
    "start_time": "2024-09-11T16:33:03.767Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-11T16:33:03.772Z"
   },
   {
    "duration": 8,
    "start_time": "2024-09-11T16:33:03.782Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-11T16:33:03.792Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-11T17:16:53.283Z"
   },
   {
    "duration": 25,
    "start_time": "2024-09-11T17:49:48.943Z"
   },
   {
    "duration": 757,
    "start_time": "2024-09-12T02:42:51.316Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-12T02:42:52.075Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-12T02:42:52.091Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-12T02:42:52.100Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-12T02:42:52.105Z"
   },
   {
    "duration": 236,
    "start_time": "2024-09-12T02:42:52.112Z"
   },
   {
    "duration": 24,
    "start_time": "2024-09-12T02:43:21.736Z"
   },
   {
    "duration": 25,
    "start_time": "2024-09-12T02:43:34.265Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-12T02:44:00.893Z"
   },
   {
    "duration": 8,
    "start_time": "2024-09-12T02:44:00.898Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-12T02:44:00.907Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-12T02:44:00.915Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-12T02:44:00.920Z"
   },
   {
    "duration": 25,
    "start_time": "2024-09-12T02:44:00.928Z"
   },
   {
    "duration": 207,
    "start_time": "2024-09-12T02:52:00.337Z"
   },
   {
    "duration": 2,
    "start_time": "2024-09-12T02:53:02.522Z"
   },
   {
    "duration": 8,
    "start_time": "2024-09-12T02:53:02.531Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-12T02:53:02.541Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-12T02:53:02.548Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-12T02:53:02.554Z"
   },
   {
    "duration": 25,
    "start_time": "2024-09-12T02:53:02.561Z"
   },
   {
    "duration": 225,
    "start_time": "2024-09-12T02:53:02.587Z"
   },
   {
    "duration": 412,
    "start_time": "2024-09-12T02:55:52.416Z"
   },
   {
    "duration": 1525,
    "start_time": "2024-09-12T02:55:59.761Z"
   },
   {
    "duration": 713,
    "start_time": "2024-09-12T02:56:20.107Z"
   },
   {
    "duration": 203,
    "start_time": "2024-09-12T02:56:35.293Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-12T03:02:35.170Z"
   },
   {
    "duration": 15391,
    "start_time": "2024-09-12T03:16:51.940Z"
   },
   {
    "duration": 3887,
    "start_time": "2024-09-12T03:17:17.846Z"
   },
   {
    "duration": 18,
    "start_time": "2024-09-12T03:19:11.083Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-12T03:19:24.157Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-12T03:55:23.959Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-12T03:58:32.195Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-12T03:58:46.236Z"
   },
   {
    "duration": 142,
    "start_time": "2024-09-12T04:00:20.140Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-12T04:00:37.194Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-12T04:00:53.816Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-12T04:01:03.033Z"
   },
   {
    "duration": 128,
    "start_time": "2024-09-12T04:06:51.877Z"
   },
   {
    "duration": 137,
    "start_time": "2024-09-12T04:11:42.241Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-12T04:39:05.442Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-12T04:41:04.092Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-12T04:42:45.772Z"
   },
   {
    "duration": 792,
    "start_time": "2024-09-12T23:19:57.215Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-12T23:19:58.009Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-12T23:19:58.026Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-12T23:19:58.034Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-12T23:19:58.049Z"
   },
   {
    "duration": 25,
    "start_time": "2024-09-12T23:19:58.058Z"
   },
   {
    "duration": 3949,
    "start_time": "2024-09-12T23:19:58.085Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-12T23:20:02.036Z"
   },
   {
    "duration": 141,
    "start_time": "2024-09-12T23:20:02.053Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-12T23:20:02.197Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-13T00:17:57.562Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-13T21:03:12.806Z"
   },
   {
    "duration": 159,
    "start_time": "2024-09-13T21:03:18.232Z"
   },
   {
    "duration": 774,
    "start_time": "2024-09-13T21:03:25.079Z"
   },
   {
    "duration": 18,
    "start_time": "2024-09-13T21:03:25.855Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-13T21:03:25.874Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-13T21:03:25.883Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-13T21:03:25.890Z"
   },
   {
    "duration": 16,
    "start_time": "2024-09-13T21:03:25.896Z"
   },
   {
    "duration": 25,
    "start_time": "2024-09-13T21:03:25.913Z"
   },
   {
    "duration": 3914,
    "start_time": "2024-09-13T21:03:25.940Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-13T21:03:29.856Z"
   },
   {
    "duration": 149,
    "start_time": "2024-09-13T21:03:29.869Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-13T21:03:30.021Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-13T21:04:11.482Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-13T21:10:08.318Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-13T21:12:57.355Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-13T21:14:59.927Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-13T21:15:13.078Z"
   },
   {
    "duration": 24,
    "start_time": "2024-09-13T21:18:04.245Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-13T21:25:42.811Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-13T21:32:39.854Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-13T21:33:07.255Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-13T21:34:04.914Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
