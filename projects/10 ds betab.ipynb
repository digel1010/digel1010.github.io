{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los clientes de Beta Bank se están yendo, cada mes, poco a poco. Los banqueros descubrieron que es más barato salvar a los clientes existentes que atraer nuevos.\n",
    "\n",
    "Necesitamos predecir si un cliente dejará el banco pronto. Tú tienes los datos sobre el comportamiento pasado de los clientes y la terminación de contratos con el banco.\n",
    "Crea un modelo con el máximo valor F1 posible. Para aprobar la revisión, necesitas un valor F1 de al menos 0.59. Verifica F1 para el conjunto de prueba. \n",
    "\n",
    "Además, debes medir la métrica AUC-ROC y compararla con el valor F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Beta Bank, la retención de clientes es una prioridad crítica debido a una creciente tasa de abandono por parte de los usuarios. Atraer nuevos clientes resulta más costoso que mantener a los actuales, lo que hace esencial identificar y retener a aquellos en riesgo de abandonar el banco. \n",
    "\n",
    "Este proyecto tiene como objetivo desarrollar un modelo predictivo para determinar la probabilidad de que un cliente abandone el banco en el futuro cercano. Utilizando datos históricos sobre el comportamiento de los clientes, se busca construir un modelo que maximice el valor F1, con un umbral mínimo de 0.59 para su validación. Además, se evaluará el desempeño del modelo a través de la métrica AUC-ROC, proporcionando una comparación adicional con el valor F1 para asegurar una evaluación exhaustiva del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos todas las librerias que creemos que vamos a utilizar\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el archivo en un dataframe\n",
    "\n",
    "df = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 14)\n",
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#validamos las dimensiones del dataframe (usamos shape) e imprimimos las primeras filas (usamos head)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print()\n",
    "\n",
    "#mostramos la informacion del dataframe con el metodo info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correción de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   row_number        10000 non-null  int64  \n",
      " 1   customer_id       10000 non-null  int64  \n",
      " 2   surname           10000 non-null  object \n",
      " 3   credit_score      10000 non-null  int64  \n",
      " 4   geography         10000 non-null  object \n",
      " 5   gender            10000 non-null  object \n",
      " 6   age               10000 non-null  int64  \n",
      " 7   tenure            9091 non-null   float64\n",
      " 8   balance           10000 non-null  float64\n",
      " 9   num_of_products   10000 non-null  int64  \n",
      " 10  has_cr_card       10000 non-null  int64  \n",
      " 11  is_active_member  10000 non-null  int64  \n",
      " 12  estimated_salary  10000 non-null  float64\n",
      " 13  exited            10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#procedemos a cambiar los nombres de columnas ya que cuentan con mayusculas, no  tiene _ en los nombres de mas de 2 palabras.\n",
    "\n",
    "# creamos una lista con los nombres correctos\n",
    "new_columns = ['row_number','customer_id', 'surname', 'credit_score', \n",
    "               'geography', 'gender', 'age', 'tenure', 'balance', 'num_of_products', \n",
    "               'has_cr_card', 'is_active_member', 'estimated_salary', 'exited']\n",
    "\n",
    "# Asignamos los nuevos nombres de columnas\n",
    "df.columns = new_columns\n",
    "\n",
    "# mostramos nuevamente la informacion del dataframe para ver los nuevos nombres de columnas\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   row_number        10000 non-null  int64  \n",
      " 1   customer_id       10000 non-null  int64  \n",
      " 2   surname           10000 non-null  object \n",
      " 3   credit_score      10000 non-null  int64  \n",
      " 4   geography         10000 non-null  object \n",
      " 5   gender            10000 non-null  object \n",
      " 6   age               10000 non-null  int64  \n",
      " 7   tenure            9091 non-null   Int64  \n",
      " 8   balance           10000 non-null  float64\n",
      " 9   num_of_products   10000 non-null  int64  \n",
      " 10  has_cr_card       10000 non-null  int64  \n",
      " 11  is_active_member  10000 non-null  int64  \n",
      " 12  estimated_salary  10000 non-null  float64\n",
      " 13  exited            10000 non-null  int64  \n",
      "dtypes: Int64(1), float64(2), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#validamos el tipo de datos y convertimos la columna 'Tenure' al tipo entero(int64) \n",
    "df['tenure'] = df['tenure'].astype('Int64') \n",
    "\n",
    "#validamos el cambio del tipo de datos con el metodo info()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customer_id       10000 non-null  int64  \n",
      " 1   credit_score      10000 non-null  int64  \n",
      " 2   geography         10000 non-null  object \n",
      " 3   gender            10000 non-null  object \n",
      " 4   age               10000 non-null  int64  \n",
      " 5   tenure            9091 non-null   Int64  \n",
      " 6   balance           10000 non-null  float64\n",
      " 7   num_of_products   10000 non-null  int64  \n",
      " 8   has_cr_card       10000 non-null  int64  \n",
      " 9   is_active_member  10000 non-null  int64  \n",
      " 10  estimated_salary  10000 non-null  float64\n",
      " 11  exited            10000 non-null  int64  \n",
      "dtypes: Int64(1), float64(2), int64(7), object(2)\n",
      "memory usage: 947.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos columnas que son irrelevantes para nuestros calculos: row_number, surname\n",
    "df = df.drop(['row_number', 'surname'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicados y valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# validamos si tenemos valores duplicados en el dataframe con el metodo duplicated\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id           0\n",
      "credit_score          0\n",
      "geography             0\n",
      "gender                0\n",
      "age                   0\n",
      "tenure              909\n",
      "balance               0\n",
      "num_of_products       0\n",
      "has_cr_card           0\n",
      "is_active_member      0\n",
      "estimated_salary      0\n",
      "exited                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#validamos si tenemos valores ausentes en el dataframe con el metodo isna\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Rellamos los valores ausentes de 'tenure' con la mediana, usamos el metodo fillna\n",
    "\n",
    "tenure_median = df['tenure'].median()\n",
    "tenure_median = int(tenure_median) #colocamos el valor de la mediana como numero entero.\n",
    "\n",
    "df['tenure'].fillna(tenure_median, inplace= True)\n",
    "\n",
    "#validamos nuevamente si tenemos valores ausentes en la columna 'tenure'\n",
    "print(df['tenure'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen estadístico de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        customer_id  credit_score           age       tenure        balance  \\\n",
      "count  1.000000e+04  10000.000000  10000.000000  10000.00000   10000.000000   \n",
      "mean   1.569094e+07    650.528800     38.921800      4.99790   76485.889288   \n",
      "std    7.193619e+04     96.653299     10.487806      2.76001   62397.405202   \n",
      "min    1.556570e+07    350.000000     18.000000      0.00000       0.000000   \n",
      "25%    1.562853e+07    584.000000     32.000000      3.00000       0.000000   \n",
      "50%    1.569074e+07    652.000000     37.000000      5.00000   97198.540000   \n",
      "75%    1.575323e+07    718.000000     44.000000      7.00000  127644.240000   \n",
      "max    1.581569e+07    850.000000     92.000000     10.00000  250898.090000   \n",
      "\n",
      "       num_of_products  has_cr_card  is_active_member  estimated_salary  \\\n",
      "count     10000.000000  10000.00000      10000.000000      10000.000000   \n",
      "mean          1.530200      0.70550          0.515100     100090.239881   \n",
      "std           0.581654      0.45584          0.499797      57510.492818   \n",
      "min           1.000000      0.00000          0.000000         11.580000   \n",
      "25%           1.000000      0.00000          0.000000      51002.110000   \n",
      "50%           1.000000      1.00000          1.000000     100193.915000   \n",
      "75%           2.000000      1.00000          1.000000     149388.247500   \n",
      "max           4.000000      1.00000          1.000000     199992.480000   \n",
      "\n",
      "             exited  \n",
      "count  10000.000000  \n",
      "mean       0.203700  \n",
      "std        0.402769  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        0.000000  \n",
      "max        1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Mostramos un resumen estadístico de las variables utilizando el metodo describe\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id  credit_score  age  tenure    balance  num_of_products  \\\n",
      "0     15634602           619   42       2       0.00                1   \n",
      "1     15647311           608   41       1   83807.86                1   \n",
      "2     15619304           502   42       8  159660.80                3   \n",
      "3     15701354           699   39       1       0.00                2   \n",
      "4     15737888           850   43       2  125510.82                1   \n",
      "\n",
      "   has_cr_card  is_active_member  estimated_salary  exited  geography_Germany  \\\n",
      "0            1                 1         101348.88       1                  0   \n",
      "1            0                 1         112542.58       0                  0   \n",
      "2            1                 0         113931.57       1                  0   \n",
      "3            0                 0          93826.63       0                  0   \n",
      "4            1                 1          79084.10       0                  0   \n",
      "\n",
      "   geography_Spain  gender_Male  \n",
      "0                0            0  \n",
      "1                1            0  \n",
      "2                0            0  \n",
      "3                0            0  \n",
      "4                1            0  \n"
     ]
    }
   ],
   "source": [
    "#usamos la tecnica One-Hot Encoding para procesar caracteristicas categoricas\n",
    "\n",
    "df_ohe = pd.get_dummies(df, drop_first= True)\n",
    "print(df_ohe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id  credit_score       age    tenure   balance  num_of_products  \\\n",
      "0     15634602     -0.326221  0.293517 -1.086246 -1.225848        -0.911583   \n",
      "1     15647311     -0.440036  0.198164 -1.448581  0.117350        -0.911583   \n",
      "2     15619304     -1.536794  0.293517  1.087768  1.333053         2.527057   \n",
      "3     15701354      0.501521  0.007457 -1.448581 -1.225848         0.807737   \n",
      "4     15737888      2.063884  0.388871 -1.086246  0.785728        -0.911583   \n",
      "\n",
      "   has_cr_card  is_active_member  estimated_salary  exited  geography_Germany  \\\n",
      "0            1                 1          0.021886       1                  0   \n",
      "1            0                 1          0.216534       0                  0   \n",
      "2            1                 0          0.240687       1                  0   \n",
      "3            0                 0         -0.108918       0                  0   \n",
      "4            1                 1         -0.365276       0                  0   \n",
      "\n",
      "   geography_Spain  gender_Male  \n",
      "0                0            0  \n",
      "1                1            0  \n",
      "2                0            0  \n",
      "3                0            0  \n",
      "4                1            0  \n"
     ]
    }
   ],
   "source": [
    "#estandarizamos los datos de las caracteristicas numericas con el escalado de caracteristicas\n",
    "\n",
    "# definimos las columnas numéricas que necesitan escalado\n",
    "numerical_columns = ['credit_score', 'age', 'tenure', 'balance', 'num_of_products', 'estimated_salary']\n",
    "\n",
    "scaler = StandardScaler()  #creamos la instancia del escalador\n",
    "\n",
    "# Ajustamos el escalador a los datos y transformar las columnas numéricas\n",
    "df_ohe[numerical_columns] = scaler.fit_transform(df_ohe[numerical_columns])\n",
    "\n",
    "# mostramos los datos escalados\n",
    "print(df_ohe.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se valida el dataframe mostrando la informacion con el metodo info, en el cual evidenciamos que los tipos de datos de cada columna son correctos, excepto el de la columna 'tenure' el cual se procede a cambiar a tipo de  dato entero; se eliminan las columnas irrelevantes para nuestro analisis como lo son 'row_number' y 'surname'. \n",
    "Adicionalmente se revisa si tenemos duplicados lo cual nos da cero y valores ausentes 909, los cuales no se deberian eliminar ya que son datos considerables de clientes, para lo cual se procede a rellenar dichos valores ausentes con la mediana. ademas se realiza un resumen estadistico del dataframe llamando al metodo describe, en el cual podemos ver informacion estadistica como el promedio, valores minimos y maximos, desviacion estandar, etc.\n",
    "\n",
    "Se procede a usar pd.get_dummies() para procesar caracteristicas categoricas ya que que es más apropiada para características categóricas que no tienen un orden y se estandarizó los datos de las caracteristicas numericas con StandardScaler() para que todas las caracteristicas se consideren igualmente importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibrio de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Revisamos si las clases en la columna objetivo 'Exited' están equilibradas.\n",
    "class_frequency = df['exited'].value_counts(normalize =  True)\n",
    "\n",
    "print(class_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos las caracteristicas y nuestro objetivo\n",
    "features = df_ohe.drop('exited', axis=1)\n",
    "target = df_ohe['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividimos los datos en conjunto de entrenamiento, validacion y prueba \n",
    "\n",
    "# dividimos el entrenamiento (60%) y un conjunto combinado de validación/prueba (40%)\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=0.40, random_state=12345)\n",
    "\n",
    "# ahora dividimos el conjunto combinado (40%) en la mitad para obtener validacion 20% y prueba 20%\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_temp, target_temp, test_size=0.50, random_state=12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (sin tratar el desequilibrio): 0.5705705705705705\n"
     ]
    }
   ],
   "source": [
    "#entrenamos el modelo\n",
    "model = RandomForestClassifier(random_state=12345, n_estimators=100)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predicted_valid = model.predict(features_valid) # Realizamos predicciones en el conjunto de validación\n",
    "\n",
    "#calculamos el valor de F1 y lo mostramos\n",
    "print('F1 Score (sin tratar el desequilibrio):', f1_score(target_valid, predicted_valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtuvimos del modelo un valor F1 de  0.559 y podriamos decir que esta cercano al solicitado en el proyecto(0.59), teniendo en cuenta que no abordamos el desequilibrio de las clases lo que podria estar afectando a nuestro modelo, este modelo sera nuestra referencia para ver y comparar las mejoras a traves del equilibrio de clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejora de la calidad del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobremuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previamente ya dividimos nuestros datos en entrenamiento y validacion: features_train, features_valid, target_train, target_valid\n",
    "\n",
    "# Definimos la función de sobremuestreo\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]  # Separamos la clase mayor (exited = 0) y la clase menor (exited = 1)\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    # Duplicamos las observaciones de la clase menor\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    # mezclamos el conjunto de datos resultante\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# Aplicamos el sobremuestreo con una repetición de 10\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Bosque aleatorio con el conjunto sobremuestreado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Sobremuestreo - Bosque Aleatorio): 0.6300768386388584\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(random_state=12345, n_estimators=100, class_weight = 'balanced', max_depth= 10)\n",
    "model1.fit(features_upsampled, target_upsampled)  #entrenamos el modelo\n",
    "\n",
    "predicted_valid1 = model1.predict(features_valid) # Realizamos predicciones en el conjunto de validación\n",
    "\n",
    "#calculamos el valor de F1 y lo mostramos\n",
    "print('F1 Score (Sobremuestreo - Bosque Aleatorio):', f1_score(target_valid, predicted_valid1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Arbol de decisión con el conjunto sobremuestreado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Sobremuestreo - Arbol de decisión): 0.5991561181434598\n"
     ]
    }
   ],
   "source": [
    "model2 = DecisionTreeClassifier(random_state=12345, class_weight = 'balanced', max_depth= 5)\n",
    "model2.fit(features_upsampled, target_upsampled)  #entrenamos el modelo\n",
    "\n",
    "predicted_valid2 = model2.predict(features_valid)  # Realizamos predicciones en el conjunto de validación\n",
    "\n",
    "#calculamos el valor de F1 y lo mostramos\n",
    "print('F1 Score (Sobremuestreo - Arbol de decisión):', f1_score(target_valid, predicted_valid2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo regresion logistica con el conjunto sobremuestreado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Sobremuestreo - regresion logistica): 0.3457402812241522\n"
     ]
    }
   ],
   "source": [
    "model3 = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model3.fit(features_upsampled, target_upsampled)  #entrenamos el modelo\n",
    "\n",
    "predicted_valid3 = model3.predict(features_valid)  # Realizamos predicciones en el conjunto de validación\n",
    "\n",
    "#calculamos el valor de F1 y lo mostramos\n",
    "print('F1 Score (Sobremuestreo - regresion logistica):', f1_score(target_valid, predicted_valid3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previamente ya dividimos nuestros datos en entrenamiento y validacion: features_train, features_valid, target_train, target_valid\n",
    "\n",
    "# Definimos la función de submuestreo\n",
    "def downsample(features, target, fraction):    \n",
    "    features_zeros = features[target == 0]  # Separamos la clase mayor (exited = 0) y la clase menor (exited = 1)\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "     \n",
    "    #usamos la función sample() para eliminar aleatoriamente una proporción de las observaciones de la clase mayor \n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [features_ones])\n",
    "    \n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [target_ones])\n",
    "    \n",
    "    # mezclamos el conjunto de datos resultante\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "# Aplicamos el submuestreo con una fraccion de 0.1\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Bosque aleatorio con el conjunto submuestreado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Submuestreo - Bosque Aleatorio): 0.5740402193784278\n"
     ]
    }
   ],
   "source": [
    "model4 = RandomForestClassifier(random_state=12345, n_estimators=100, class_weight = 'balanced', max_depth= 3)\n",
    "model4.fit(features_downsampled, target_downsampled)  #entrenamos el modelo\n",
    "\n",
    "predicted_valid4 = model4.predict(features_valid) # Realizamos predicciones en el conjunto de validación\n",
    "\n",
    "#calculamos el valor de F1 y lo mostramos\n",
    "print('F1 Score (Submuestreo - Bosque Aleatorio):', f1_score(target_valid, predicted_valid4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Arbol de decision con el conjunto submuestreado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Submuestreo - Arbol de decisión): 0.511744966442953\n"
     ]
    }
   ],
   "source": [
    "model5 = DecisionTreeClassifier(random_state=12345, class_weight = 'balanced', max_depth= 7)\n",
    "model5.fit(features_downsampled, target_downsampled)  #entrenamos el modelo\n",
    "\n",
    "predicted_valid5 = model5.predict(features_valid)  # Realizamos predicciones en el conjunto de validación\n",
    "\n",
    "#calculamos el valor de F1 y lo mostramos\n",
    "print('F1 Score (Submuestreo - Arbol de decisión):', f1_score(target_valid, predicted_valid5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo regresion logistica con el conjunto submuestreado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Submuestreo - regresion logistica): 0.3457402812241522\n"
     ]
    }
   ],
   "source": [
    "model6 = LogisticRegression(random_state=12345, solver='liblinear', class_weight = 'balanced')\n",
    "model6.fit(features_downsampled, target_downsampled)  #entrenamos el modelo\n",
    "\n",
    "predicted_valid6 = model6.predict(features_valid)  # Realizamos predicciones en el conjunto de validación\n",
    "\n",
    "#calculamos el valor de F1 y lo mostramos\n",
    "print('F1 Score (Submuestreo - regresion logistica):', f1_score(target_valid, predicted_valid6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizaron tecnicas de Sobremuestreo y submuestreo para los diferentes tipos de modelos, como lo son bosque aleatorio, arbol de decision y regresion logistica. Para sobremuestreo el bosque aleatorio arrojo el mas alto valor de F1 siendo 0.630, seguido del arbol de decision en sobremuestreo con un valor de 0.599. para el submuestreo el valor mas alto de F1 lo tiene el modelo de bosque aleatorio (0.57), pero no mas que el valor de sobremuestreo. la regresion logistica en ambas tecnicas nos da un valor de 0.347 siendo el modelo con menor valor de todos los modelos en ambas tecnicas.\n",
    "\n",
    "Aunque el submuestreo también produce buenos resultados, el sobremuestreo parece ofrecer un F1 score más alto. Esto sugiere que el bosque aleatorio puede beneficiarse más de un conjunto de datos con más ejemplos de la clase minoritaria, como ocurre con el sobremuestreo. por lo anterior se procedera a realizar la prueba final con el modelo de bosque aleatorio sobremuestreado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score prueba final: 0.6127292340884574\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo de bosque aleatorio sobremuestreado\n",
    "\n",
    "final_model = RandomForestClassifier(random_state=12345, n_estimators=100, class_weight = 'balanced', max_depth= 10)\n",
    "final_model.fit(features_upsampled, target_upsampled)  #entrenamos el modelo\n",
    "\n",
    "predicted_test = final_model.predict(features_test) # Realizamos predicciones en el conjunto de prueba\n",
    "\n",
    "#calculamos el valor de F1 y lo mostramos\n",
    "print('F1 Score prueba final:', f1_score(target_test, predicted_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score prueba final: 0.8558953994402394\n"
     ]
    }
   ],
   "source": [
    "#Validamos los valores de auc_roc\n",
    "\n",
    "probabilities_test = final_model.predict_proba(features_test) # Calculamos las probabilidades de predicción en el conjunto de prueba\n",
    "\n",
    "probabilities_one_test = probabilities_test[:, 1] #Extraemos las probabilidades de la clase positiva\n",
    "\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test) # Calculamos el valor de AUC-ROC para las predicciones\n",
    "\n",
    "print(\"AUC-ROC Score prueba final:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor de F1 0.6127 en el conjunto de prueba es un buen resultado, sobre todo si consideramos que se trata de un problema de clasificación desequilibrado y es ligeramente inferior al obtenido en el conjunto de validación (0.630), lo cual es esperado al usar un conjunto de datos diferente. adicionalmente es adecuada ya que supero el valor 0.59 minimo exigido.\n",
    "\n",
    "el valor de AUC-ROC de 0.8559 es un excelente resultado, ya que está bastante cerca de 1, lo que significa que el modelo tiene una gran capacidad para distinguir entre las clases (clientes que dejan el banco y los que no lo hacen).\n",
    "\n",
    "El modelo bosque aleatorio sobremuestreado ha mostrado ser una excelente elección para predecir si un cliente dejara el banco pronto. Con un F1 Score razonable y un AUC-ROC alto, podriamos decir que el modelo está listo para ser utilizado por Betabank\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 797,
    "start_time": "2024-09-17T22:10:33.193Z"
   },
   {
    "duration": 26,
    "start_time": "2024-09-17T22:10:33.993Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-17T22:11:23.992Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-17T22:41:03.302Z"
   },
   {
    "duration": 12,
    "start_time": "2024-09-17T22:55:46.764Z"
   },
   {
    "duration": 156,
    "start_time": "2024-09-18T17:10:56.020Z"
   },
   {
    "duration": 788,
    "start_time": "2024-09-18T17:11:04.261Z"
   },
   {
    "duration": 27,
    "start_time": "2024-09-18T17:11:05.051Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-18T17:11:05.080Z"
   },
   {
    "duration": 17,
    "start_time": "2024-09-18T17:11:05.096Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-18T17:11:05.115Z"
   },
   {
    "duration": 77,
    "start_time": "2024-09-18T17:11:57.466Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-18T17:12:03.078Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-18T17:12:21.561Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-18T17:13:42.481Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-18T17:17:13.612Z"
   },
   {
    "duration": 12,
    "start_time": "2024-09-18T17:17:36.169Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-18T17:18:42.408Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-18T17:23:17.053Z"
   },
   {
    "duration": 12,
    "start_time": "2024-09-18T17:23:23.651Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-18T17:23:42.277Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-18T17:24:14.827Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-18T17:25:45.087Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-18T17:26:07.074Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-18T17:26:07.079Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-18T17:26:07.097Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-18T17:26:07.112Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-18T17:26:07.123Z"
   },
   {
    "duration": 534,
    "start_time": "2024-09-18T17:36:55.679Z"
   },
   {
    "duration": 50,
    "start_time": "2024-09-18T17:37:01.479Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-18T17:37:06.357Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-18T17:38:07.784Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-18T17:42:39.582Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-18T17:42:43.547Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-18T17:43:37.183Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-18T17:55:37.089Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-18T17:56:11.464Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-18T17:56:33.441Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-18T18:02:22.690Z"
   },
   {
    "duration": 60,
    "start_time": "2024-09-18T18:17:39.609Z"
   },
   {
    "duration": 27,
    "start_time": "2024-09-18T18:49:20.834Z"
   },
   {
    "duration": 769,
    "start_time": "2024-09-19T03:25:02.601Z"
   },
   {
    "duration": 29,
    "start_time": "2024-09-19T03:25:03.372Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-19T03:25:03.402Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-19T03:25:03.419Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-19T03:25:03.430Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-19T03:25:03.446Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-19T03:25:03.455Z"
   },
   {
    "duration": 8,
    "start_time": "2024-09-19T03:25:03.461Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-19T03:25:03.471Z"
   },
   {
    "duration": 26,
    "start_time": "2024-09-19T03:25:03.477Z"
   },
   {
    "duration": 61,
    "start_time": "2024-09-19T03:46:16.134Z"
   },
   {
    "duration": 222,
    "start_time": "2024-09-19T03:46:32.892Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-19T03:46:51.811Z"
   },
   {
    "duration": 36,
    "start_time": "2024-09-19T03:46:57.053Z"
   },
   {
    "duration": 37,
    "start_time": "2024-09-19T03:47:04.700Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-19T04:20:19.914Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-19T04:43:03.849Z"
   },
   {
    "duration": 17,
    "start_time": "2024-09-19T04:43:03.855Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-19T04:43:03.874Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-19T04:43:03.890Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-19T04:43:03.902Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-19T04:43:03.912Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-19T04:43:03.944Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-19T04:43:03.952Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-19T04:43:03.958Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-19T04:43:03.969Z"
   },
   {
    "duration": 23,
    "start_time": "2024-09-19T04:43:03.977Z"
   },
   {
    "duration": 43,
    "start_time": "2024-09-19T04:43:04.002Z"
   },
   {
    "duration": 2,
    "start_time": "2024-09-19T04:43:04.047Z"
   },
   {
    "duration": 25,
    "start_time": "2024-09-19T04:43:04.051Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-19T04:43:04.077Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-19T04:46:03.623Z"
   },
   {
    "duration": 12,
    "start_time": "2024-09-19T04:49:45.778Z"
   },
   {
    "duration": 722,
    "start_time": "2024-09-19T04:51:59.321Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-19T04:52:34.950Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-19T04:52:34.957Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-19T04:52:34.973Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-19T04:52:34.988Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-19T04:52:35.001Z"
   },
   {
    "duration": 35,
    "start_time": "2024-09-19T04:52:35.012Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-19T04:52:35.048Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-19T04:52:35.056Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-19T04:52:35.065Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-19T04:52:35.074Z"
   },
   {
    "duration": 23,
    "start_time": "2024-09-19T04:52:35.081Z"
   },
   {
    "duration": 43,
    "start_time": "2024-09-19T04:52:35.106Z"
   },
   {
    "duration": 2,
    "start_time": "2024-09-19T04:52:35.151Z"
   },
   {
    "duration": 26,
    "start_time": "2024-09-19T04:52:35.155Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-19T04:52:35.184Z"
   },
   {
    "duration": 20,
    "start_time": "2024-09-19T04:59:58.518Z"
   },
   {
    "duration": 769,
    "start_time": "2024-09-19T15:30:07.552Z"
   },
   {
    "duration": 30,
    "start_time": "2024-09-19T15:30:08.324Z"
   },
   {
    "duration": 16,
    "start_time": "2024-09-19T15:30:08.356Z"
   },
   {
    "duration": 12,
    "start_time": "2024-09-19T15:30:08.374Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-19T15:30:08.388Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-19T15:30:08.400Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-19T15:30:08.411Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-19T15:30:08.420Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-19T15:30:08.426Z"
   },
   {
    "duration": 62,
    "start_time": "2024-09-19T15:30:08.433Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-19T15:30:08.497Z"
   },
   {
    "duration": 18,
    "start_time": "2024-09-19T15:30:08.510Z"
   },
   {
    "duration": 24,
    "start_time": "2024-09-19T15:30:08.530Z"
   },
   {
    "duration": 30,
    "start_time": "2024-09-19T15:30:08.556Z"
   },
   {
    "duration": 769,
    "start_time": "2024-09-19T21:04:17.965Z"
   },
   {
    "duration": 31,
    "start_time": "2024-09-19T21:04:18.737Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-19T21:04:18.769Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-19T21:04:18.786Z"
   },
   {
    "duration": 12,
    "start_time": "2024-09-19T21:04:18.800Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-19T21:04:18.814Z"
   },
   {
    "duration": 8,
    "start_time": "2024-09-19T21:04:18.826Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-19T21:04:18.835Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-19T21:04:18.843Z"
   },
   {
    "duration": 27,
    "start_time": "2024-09-19T21:04:18.887Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-19T21:04:18.915Z"
   },
   {
    "duration": 17,
    "start_time": "2024-09-19T21:04:18.927Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-19T21:04:18.945Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-19T21:19:49.733Z"
   },
   {
    "duration": 52,
    "start_time": "2024-09-19T21:21:02.163Z"
   },
   {
    "duration": 51,
    "start_time": "2024-09-19T21:22:05.176Z"
   },
   {
    "duration": 354,
    "start_time": "2024-09-19T21:25:33.265Z"
   },
   {
    "duration": 833,
    "start_time": "2024-09-19T21:25:50.582Z"
   },
   {
    "duration": 419,
    "start_time": "2024-09-19T21:26:04.105Z"
   },
   {
    "duration": 96,
    "start_time": "2024-09-19T21:26:10.843Z"
   },
   {
    "duration": 420,
    "start_time": "2024-09-19T21:26:18.866Z"
   },
   {
    "duration": 915,
    "start_time": "2024-09-19T21:26:24.996Z"
   },
   {
    "duration": 20,
    "start_time": "2024-09-19T21:28:53.621Z"
   },
   {
    "duration": 811,
    "start_time": "2024-09-19T21:30:27.979Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-19T22:12:51.519Z"
   },
   {
    "duration": 822,
    "start_time": "2024-09-19T22:13:03.522Z"
   },
   {
    "duration": 831,
    "start_time": "2024-09-19T22:13:24.230Z"
   },
   {
    "duration": 242,
    "start_time": "2024-09-19T22:14:32.796Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-19T22:15:22.547Z"
   },
   {
    "duration": 1708,
    "start_time": "2024-09-19T22:19:46.658Z"
   },
   {
    "duration": 1693,
    "start_time": "2024-09-19T22:21:12.888Z"
   },
   {
    "duration": 1628,
    "start_time": "2024-09-19T22:22:43.372Z"
   },
   {
    "duration": 1648,
    "start_time": "2024-09-19T22:23:05.479Z"
   },
   {
    "duration": 39,
    "start_time": "2024-09-19T22:28:34.030Z"
   },
   {
    "duration": 1676,
    "start_time": "2024-09-19T22:30:20.213Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-19T22:33:49.083Z"
   },
   {
    "duration": 78,
    "start_time": "2024-09-19T22:33:57.423Z"
   },
   {
    "duration": 79,
    "start_time": "2024-09-19T22:34:24.597Z"
   },
   {
    "duration": 21,
    "start_time": "2024-09-19T22:46:51.811Z"
   },
   {
    "duration": 20,
    "start_time": "2024-09-19T22:49:37.875Z"
   },
   {
    "duration": 21,
    "start_time": "2024-09-19T22:49:52.156Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-19T23:05:50.002Z"
   },
   {
    "duration": 270,
    "start_time": "2024-09-19T23:08:25.054Z"
   },
   {
    "duration": 265,
    "start_time": "2024-09-19T23:08:44.539Z"
   },
   {
    "duration": 22,
    "start_time": "2024-09-19T23:10:15.157Z"
   },
   {
    "duration": 19,
    "start_time": "2024-09-19T23:11:41.412Z"
   },
   {
    "duration": 280,
    "start_time": "2024-09-19T23:11:59.640Z"
   },
   {
    "duration": 18,
    "start_time": "2024-09-19T23:12:04.587Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-19T23:13:20.806Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-19T23:13:33.001Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-19T23:13:41.107Z"
   },
   {
    "duration": 2499,
    "start_time": "2024-09-19T23:20:02.404Z"
   },
   {
    "duration": 3367,
    "start_time": "2024-09-19T23:20:14.724Z"
   },
   {
    "duration": 2522,
    "start_time": "2024-09-19T23:20:30.958Z"
   },
   {
    "duration": 1631,
    "start_time": "2024-09-19T23:21:43.271Z"
   },
   {
    "duration": 1353,
    "start_time": "2024-09-19T23:22:11.614Z"
   },
   {
    "duration": 66,
    "start_time": "2024-09-19T23:22:48.936Z"
   },
   {
    "duration": 1631,
    "start_time": "2024-09-19T23:23:01.905Z"
   },
   {
    "duration": 1678,
    "start_time": "2024-09-19T23:25:04.369Z"
   },
   {
    "duration": 1349,
    "start_time": "2024-09-19T23:25:12.245Z"
   },
   {
    "duration": 1182,
    "start_time": "2024-09-19T23:25:22.169Z"
   },
   {
    "duration": 875,
    "start_time": "2024-09-19T23:25:30.524Z"
   },
   {
    "duration": 969,
    "start_time": "2024-09-19T23:25:38.074Z"
   },
   {
    "duration": 1142,
    "start_time": "2024-09-19T23:25:43.963Z"
   },
   {
    "duration": 1184,
    "start_time": "2024-09-19T23:25:50.712Z"
   },
   {
    "duration": 79,
    "start_time": "2024-09-19T23:26:01.896Z"
   },
   {
    "duration": 62,
    "start_time": "2024-09-19T23:26:09.969Z"
   },
   {
    "duration": 59,
    "start_time": "2024-09-19T23:26:17.743Z"
   },
   {
    "duration": 63,
    "start_time": "2024-09-19T23:26:25.924Z"
   },
   {
    "duration": 1716,
    "start_time": "2024-09-19T23:27:04.642Z"
   },
   {
    "duration": 1171,
    "start_time": "2024-09-19T23:27:14.729Z"
   },
   {
    "duration": 58,
    "start_time": "2024-09-19T23:28:22.287Z"
   },
   {
    "duration": 17,
    "start_time": "2024-09-19T23:28:36.959Z"
   },
   {
    "duration": 224,
    "start_time": "2024-09-19T23:30:59.289Z"
   },
   {
    "duration": 248,
    "start_time": "2024-09-19T23:31:07.120Z"
   },
   {
    "duration": 242,
    "start_time": "2024-09-19T23:31:13.648Z"
   },
   {
    "duration": 210,
    "start_time": "2024-09-19T23:31:24.104Z"
   },
   {
    "duration": 198,
    "start_time": "2024-09-19T23:31:35.394Z"
   },
   {
    "duration": 182,
    "start_time": "2024-09-19T23:31:51.031Z"
   },
   {
    "duration": 151,
    "start_time": "2024-09-19T23:32:02.321Z"
   },
   {
    "duration": 174,
    "start_time": "2024-09-19T23:32:07.862Z"
   },
   {
    "duration": 189,
    "start_time": "2024-09-19T23:32:13.785Z"
   },
   {
    "duration": 271,
    "start_time": "2024-09-19T23:32:30.338Z"
   },
   {
    "duration": 185,
    "start_time": "2024-09-19T23:32:40.971Z"
   },
   {
    "duration": 353,
    "start_time": "2024-09-19T23:32:46.955Z"
   },
   {
    "duration": 183,
    "start_time": "2024-09-19T23:32:53.937Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-19T23:33:05.998Z"
   },
   {
    "duration": 17,
    "start_time": "2024-09-19T23:33:14.163Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-19T23:33:23.328Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-19T23:33:32.200Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-19T23:33:37.362Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-19T23:33:45.365Z"
   },
   {
    "duration": 18,
    "start_time": "2024-09-19T23:33:50.461Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-19T23:33:56.043Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-20T00:29:00.001Z"
   },
   {
    "duration": 644,
    "start_time": "2024-09-20T00:29:12.149Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-20T00:29:35.042Z"
   },
   {
    "duration": 910,
    "start_time": "2024-09-20T00:29:41.180Z"
   },
   {
    "duration": 51,
    "start_time": "2024-09-20T00:29:59.735Z"
   },
   {
    "duration": 21,
    "start_time": "2024-09-20T00:30:04.482Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-20T00:30:18.456Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-20T00:30:25.489Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-20T00:30:25.495Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-20T00:30:25.510Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-20T00:30:25.525Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-20T00:30:25.538Z"
   },
   {
    "duration": 42,
    "start_time": "2024-09-20T00:30:25.551Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-20T00:30:25.595Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-20T00:30:25.603Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-20T00:30:25.609Z"
   },
   {
    "duration": 24,
    "start_time": "2024-09-20T00:30:25.616Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-20T00:30:25.642Z"
   },
   {
    "duration": 19,
    "start_time": "2024-09-20T00:30:25.687Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-20T00:30:25.708Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-20T00:30:25.715Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-20T00:30:25.720Z"
   },
   {
    "duration": 674,
    "start_time": "2024-09-20T00:30:25.729Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-20T00:30:26.404Z"
   },
   {
    "duration": 930,
    "start_time": "2024-09-20T00:30:26.416Z"
   },
   {
    "duration": 59,
    "start_time": "2024-09-20T00:30:27.348Z"
   },
   {
    "duration": 18,
    "start_time": "2024-09-20T00:30:27.408Z"
   },
   {
    "duration": 59,
    "start_time": "2024-09-20T00:30:27.428Z"
   },
   {
    "duration": 239,
    "start_time": "2024-09-20T00:30:27.489Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-20T00:30:27.730Z"
   },
   {
    "duration": 43,
    "start_time": "2024-09-20T00:30:27.744Z"
   },
   {
    "duration": 1068,
    "start_time": "2024-09-20T00:32:12.254Z"
   },
   {
    "duration": 1145,
    "start_time": "2024-09-20T00:32:21.670Z"
   },
   {
    "duration": 1086,
    "start_time": "2024-09-20T00:32:28.487Z"
   },
   {
    "duration": 1019,
    "start_time": "2024-09-20T00:32:37.380Z"
   },
   {
    "duration": 926,
    "start_time": "2024-09-20T00:32:44.299Z"
   },
   {
    "duration": 1044,
    "start_time": "2024-09-20T00:32:50.899Z"
   },
   {
    "duration": 1612,
    "start_time": "2024-09-20T00:32:59.421Z"
   },
   {
    "duration": 2103,
    "start_time": "2024-09-20T00:33:08.742Z"
   },
   {
    "duration": 1045,
    "start_time": "2024-09-20T00:33:16.817Z"
   },
   {
    "duration": 55,
    "start_time": "2024-09-20T00:33:49.284Z"
   },
   {
    "duration": 46,
    "start_time": "2024-09-20T00:33:56.011Z"
   },
   {
    "duration": 52,
    "start_time": "2024-09-20T00:34:05.874Z"
   },
   {
    "duration": 38,
    "start_time": "2024-09-20T00:34:11.276Z"
   },
   {
    "duration": 38,
    "start_time": "2024-09-20T00:34:19.732Z"
   },
   {
    "duration": 31,
    "start_time": "2024-09-20T00:37:01.167Z"
   },
   {
    "duration": 1043,
    "start_time": "2024-09-20T00:42:21.610Z"
   },
   {
    "duration": 1110,
    "start_time": "2024-09-20T00:42:28.416Z"
   },
   {
    "duration": 36,
    "start_time": "2024-09-20T00:42:39.668Z"
   },
   {
    "duration": 37,
    "start_time": "2024-09-20T00:42:54.460Z"
   },
   {
    "duration": 182,
    "start_time": "2024-09-20T00:43:37.574Z"
   },
   {
    "duration": 147,
    "start_time": "2024-09-20T00:43:47.411Z"
   },
   {
    "duration": 138,
    "start_time": "2024-09-20T00:43:54.974Z"
   },
   {
    "duration": 125,
    "start_time": "2024-09-20T00:44:00.916Z"
   },
   {
    "duration": 138,
    "start_time": "2024-09-20T00:44:06.014Z"
   },
   {
    "duration": 138,
    "start_time": "2024-09-20T00:44:18.621Z"
   },
   {
    "duration": 142,
    "start_time": "2024-09-20T00:44:22.997Z"
   },
   {
    "duration": 203,
    "start_time": "2024-09-20T00:44:32.480Z"
   },
   {
    "duration": 135,
    "start_time": "2024-09-20T00:44:37.532Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-20T00:45:02.653Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-20T00:45:08.643Z"
   },
   {
    "duration": 16,
    "start_time": "2024-09-20T00:45:14.264Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-20T00:45:19.546Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-20T00:45:24.564Z"
   },
   {
    "duration": 12,
    "start_time": "2024-09-20T00:45:56.044Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-20T00:46:00.911Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-20T00:46:07.815Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-20T00:46:27.939Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-20T00:46:48.303Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-20T00:46:57.803Z"
   },
   {
    "duration": 1070,
    "start_time": "2024-09-20T01:18:08.687Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-20T01:24:54.079Z"
   },
   {
    "duration": 31,
    "start_time": "2024-09-20T01:44:37.436Z"
   },
   {
    "duration": 29,
    "start_time": "2024-09-20T01:55:19.169Z"
   },
   {
    "duration": 1100,
    "start_time": "2024-09-20T01:55:48.178Z"
   },
   {
    "duration": 30,
    "start_time": "2024-09-20T01:59:42.700Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
